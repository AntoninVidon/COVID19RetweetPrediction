{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit # pip install verstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"Data/train.csv\")\n",
    "\n",
    "# Here we split our training data into trainig and testing set. This way we can estimate the evaluation of our model without uploading to Kaggle and avoid overfitting over our evaluation dataset.\n",
    "# scsplit method is used in order to split our regression data in a stratisfied way and keep a similar distribution of retweet counts between the two sets\n",
    "X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "X_train = X_train.drop(['retweet_count'], axis=1)\n",
    "X_test = X_test.drop(['retweet_count'], axis=1)\n",
    "\n",
    "# You can examine the available features using X_train.head()\n",
    "\n",
    "# We set up an Tfidf Vectorizer that will use the top 100 tokens from the tweets. We also remove stopwords.\n",
    "# To do that we have to fit our training dataset and then transform both the training and testing dataset. \n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(X_train['text'])\n",
    "X_test = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error: 261.3492519176531\n"
     ]
    }
   ],
   "source": [
    "# Now we can train our model. Here we chose a Gradient Boosting Regressor and we set our loss function \n",
    "reg = GradientBoostingRegressor()\n",
    "# We fit our model using the training data\n",
    "reg.fit(X_train, y_train)\n",
    "# And then we predict the values for our testing set\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Prediction error:\", mean_absolute_error(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Once we finalized our features and model we can train it using the whole training set and then produce prediction for the evaluating dataset\n",
    "###################################\n",
    "# Load the evaluation data\n",
    "eval_data = pd.read_csv(\"Data/evaluation.csv\")\n",
    "# Transform our data into tfidf vectors\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "y_train = train_data['retweet_count']\n",
    "X_train = vectorizer.fit_transform(train_data['text'])\n",
    "# We fit our model using the training data\n",
    "reg = GradientBoostingRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "X_val = vectorizer.transform(eval_data['text'])\n",
    "# Predict the number of retweets for the evaluation dataset\n",
    "y_pred = reg.predict(X_val)\n",
    "# Dump the results into a file that follows the required Kaggle template\n",
    "with open(\"gbr_predictions.txt\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "    for index, prediction in enumerate(y_pred):\n",
    "        writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
