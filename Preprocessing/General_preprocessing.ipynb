{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import ComputeCleanTexts, ChangeTimeFormat, CountCommaSeparated, CountSpaceSeperated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = pd.read_csv(\"../Data/train.csv\")\n",
    "processed_eval_data = pd.read_csv(\"../Data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute clean texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean texts are tokenized, lemmatized and filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "665777it [01:47, 6202.25it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_data['clean_text'] = ComputeCleanTexts(processed_train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Smh I give up\n",
      "1 : Most of us are Human Beings, but I think you miss that boat George...\n",
      "2 : Old dirty tricks Trump, at it again...like we don't know what Fauci would say! Ha Ha Ha ha ha ha ha\n",
      "3 : Seriously..... I worked 86 hours my last check and it didn’t even come close to this....\n",
      "4 : May ALMIGHTY ALLAH have mercy on us all. Only lagosians observed real lockdown in Nigeria\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):            \n",
    "    print(i,\": \"+processed_train_data.loc[i,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : smh give\n",
      "1 : u human being think miss boat george\n",
      "2 : old dirty trick trump like know fauci would say ha ha ha ha ha ha ha\n",
      "3 : seriously worked 86 hour last check even come close\n",
      "4 : may almighty allah mercy u lagosians observed real lockdown nigeria\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):            \n",
    "    print(i,\": \"+processed_train_data.loc[i,'clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285334it [00:47, 5958.86it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data['clean_text'] = ComputeCleanTexts(processed_eval_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract time from timestamp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using timestamp, one retrieves year, month day, week day and hour of publication of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665777/665777 [01:11<00:00, 9369.07it/s] \n"
     ]
    }
   ],
   "source": [
    "processed_train_data = ChangeTimeFormat(processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285334/285334 [00:28<00:00, 10027.05it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data = ChangeTimeFormat(processed_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Replace verified boolean by 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data['user_verified'] *= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_eval_data['user_verified'] *= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count comma-separated fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665777/665777 [00:00<00:00, 1221847.40it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_data['url_count'] = CountCommaSeparated(processed_train_data, 'urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285334/285334 [00:00<00:00, 1217579.89it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data['url_count'] = CountCommaSeparated(processed_eval_data, 'urls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665777/665777 [00:00<00:00, 1337089.42it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_data['user_mentions_count'] = CountCommaSeparated(processed_train_data, 'user_mentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285334/285334 [00:00<00:00, 1491460.25it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data['user_mentions_count'] = CountCommaSeparated(processed_eval_data, 'user_mentions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665777/665777 [00:00<00:00, 1605943.71it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_data['hashtag_count'] = CountCommaSeparated(processed_train_data, 'hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285334/285334 [00:00<00:00, 1585198.80it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data['hashtag_count'] = CountCommaSeparated(processed_eval_data, 'hashtags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Count text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665777/665777 [00:01<00:00, 653432.02it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_train_data['text_length'] = CountSpaceSeperated(processed_train_data, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285334/285334 [00:00<00:00, 557593.55it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_eval_data['text_length'] = CountSpaceSeperated(processed_eval_data, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save data (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data.to_pickle(\"Data/train_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_eval_data.to_pickle(\"Data/eval_processed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save data (pytorch tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.tensor(np.array(processed_train_data[['month', 'week_day', 'day', 'hour', 'user_verified', 'user_followers_count', 'user_friends_count', 'user_mentions_count', 'url_count', 'hashtag_count', 'text_length']]), dtype=torch.float64, device='cpu')\n",
    "torch.save(train_tensor, '../Tensors/Training/12_features_tr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-92b0b62a27ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_eval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'week_day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_verified'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_followers_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_friends_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_mentions_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'url_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hashtag_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../Tensors/Testing/12_features_test.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/inf554/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.tensor(np.array(processed_eval_data[['month', 'week_day', 'day', 'hour', 'user_verified', 'user_followers_count', 'user_friends_count', 'user_mentions_count', 'url_count', 'hashtag_count', 'text_length']]), dtype=torch.float64, device='cuda')\n",
    "torch.save(test_tensor, '../Tensors/Testing/12_features_test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
